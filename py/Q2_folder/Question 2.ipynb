{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb55cf81",
   "metadata": {},
   "source": [
    "Converting CSV to PyTorch tensor: https://www.codegenes.net/blog/pytorch-dataset-from-csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "44601cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "45b89ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obj_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>delta</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>run_ID</th>\n",
       "      <th>rerun_ID</th>\n",
       "      <th>cam_col</th>\n",
       "      <th>field_ID</th>\n",
       "      <th>spec_obj_ID</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>MJD</th>\n",
       "      <th>fiber_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27815</th>\n",
       "      <td>1.237679e+18</td>\n",
       "      <td>30.918809</td>\n",
       "      <td>4.136280</td>\n",
       "      <td>21.99281</td>\n",
       "      <td>21.40838</td>\n",
       "      <td>21.15975</td>\n",
       "      <td>20.93182</td>\n",
       "      <td>20.92116</td>\n",
       "      <td>7727</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>272</td>\n",
       "      <td>9.836065e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>2.098777</td>\n",
       "      <td>8736</td>\n",
       "      <td>57400</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75509</th>\n",
       "      <td>1.237654e+18</td>\n",
       "      <td>186.387998</td>\n",
       "      <td>64.216099</td>\n",
       "      <td>20.49810</td>\n",
       "      <td>19.45201</td>\n",
       "      <td>19.03974</td>\n",
       "      <td>18.92427</td>\n",
       "      <td>18.50794</td>\n",
       "      <td>2078</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "      <td>6.756128e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800508</td>\n",
       "      <td>600</td>\n",
       "      <td>52317</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22940</th>\n",
       "      <td>1.237662e+18</td>\n",
       "      <td>239.253537</td>\n",
       "      <td>6.287921</td>\n",
       "      <td>18.05269</td>\n",
       "      <td>17.10405</td>\n",
       "      <td>16.80945</td>\n",
       "      <td>16.69879</td>\n",
       "      <td>16.67672</td>\n",
       "      <td>3894</td>\n",
       "      <td>301</td>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>2.051524e+18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>1822</td>\n",
       "      <td>53172</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59108</th>\n",
       "      <td>1.237662e+18</td>\n",
       "      <td>227.023436</td>\n",
       "      <td>32.527047</td>\n",
       "      <td>22.12350</td>\n",
       "      <td>19.75591</td>\n",
       "      <td>18.28602</td>\n",
       "      <td>16.77130</td>\n",
       "      <td>15.99146</td>\n",
       "      <td>3900</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>604</td>\n",
       "      <td>3.304670e+18</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>2935</td>\n",
       "      <td>54652</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30418</th>\n",
       "      <td>1.237679e+18</td>\n",
       "      <td>19.966213</td>\n",
       "      <td>4.396557</td>\n",
       "      <td>21.79158</td>\n",
       "      <td>22.52559</td>\n",
       "      <td>21.68066</td>\n",
       "      <td>21.58270</td>\n",
       "      <td>20.54644</td>\n",
       "      <td>7718</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>1.062195e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.940256</td>\n",
       "      <td>9434</td>\n",
       "      <td>57712</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43404</th>\n",
       "      <td>1.237665e+18</td>\n",
       "      <td>195.245179</td>\n",
       "      <td>35.437614</td>\n",
       "      <td>20.87053</td>\n",
       "      <td>19.05368</td>\n",
       "      <td>17.67823</td>\n",
       "      <td>17.16317</td>\n",
       "      <td>16.83086</td>\n",
       "      <td>4576</td>\n",
       "      <td>301</td>\n",
       "      <td>6</td>\n",
       "      <td>504</td>\n",
       "      <td>2.286720e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220472</td>\n",
       "      <td>2031</td>\n",
       "      <td>53848</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11091</th>\n",
       "      <td>1.237668e+18</td>\n",
       "      <td>218.280662</td>\n",
       "      <td>14.227425</td>\n",
       "      <td>19.72429</td>\n",
       "      <td>17.77691</td>\n",
       "      <td>16.81737</td>\n",
       "      <td>16.34801</td>\n",
       "      <td>15.96386</td>\n",
       "      <td>5322</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>3.094060e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>2748</td>\n",
       "      <td>54234</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40941</th>\n",
       "      <td>1.237679e+18</td>\n",
       "      <td>26.402946</td>\n",
       "      <td>2.342690</td>\n",
       "      <td>22.02573</td>\n",
       "      <td>21.71187</td>\n",
       "      <td>21.45149</td>\n",
       "      <td>21.38046</td>\n",
       "      <td>21.43656</td>\n",
       "      <td>7717</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>506</td>\n",
       "      <td>8.826076e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>2.199759</td>\n",
       "      <td>7839</td>\n",
       "      <td>56900</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35065</th>\n",
       "      <td>1.237670e+18</td>\n",
       "      <td>46.450690</td>\n",
       "      <td>37.019152</td>\n",
       "      <td>19.40372</td>\n",
       "      <td>18.22283</td>\n",
       "      <td>17.86272</td>\n",
       "      <td>17.73182</td>\n",
       "      <td>17.69230</td>\n",
       "      <td>5817</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>213</td>\n",
       "      <td>2.748348e+18</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.000280</td>\n",
       "      <td>2441</td>\n",
       "      <td>54065</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>1.237665e+18</td>\n",
       "      <td>159.229079</td>\n",
       "      <td>30.989822</td>\n",
       "      <td>23.65771</td>\n",
       "      <td>21.92722</td>\n",
       "      <td>20.00496</td>\n",
       "      <td>19.40892</td>\n",
       "      <td>18.98498</td>\n",
       "      <td>4576</td>\n",
       "      <td>301</td>\n",
       "      <td>1</td>\n",
       "      <td>302</td>\n",
       "      <td>1.281741e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.358106</td>\n",
       "      <td>11384</td>\n",
       "      <td>58522</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             obj_ID       alpha      delta         u         g         r  \\\n",
       "27815  1.237679e+18   30.918809   4.136280  21.99281  21.40838  21.15975   \n",
       "75509  1.237654e+18  186.387998  64.216099  20.49810  19.45201  19.03974   \n",
       "22940  1.237662e+18  239.253537   6.287921  18.05269  17.10405  16.80945   \n",
       "59108  1.237662e+18  227.023436  32.527047  22.12350  19.75591  18.28602   \n",
       "30418  1.237679e+18   19.966213   4.396557  21.79158  22.52559  21.68066   \n",
       "43404  1.237665e+18  195.245179  35.437614  20.87053  19.05368  17.67823   \n",
       "11091  1.237668e+18  218.280662  14.227425  19.72429  17.77691  16.81737   \n",
       "40941  1.237679e+18   26.402946   2.342690  22.02573  21.71187  21.45149   \n",
       "35065  1.237670e+18   46.450690  37.019152  19.40372  18.22283  17.86272   \n",
       "17194  1.237665e+18  159.229079  30.989822  23.65771  21.92722  20.00496   \n",
       "\n",
       "              i         z  run_ID  rerun_ID  cam_col  field_ID   spec_obj_ID  \\\n",
       "27815  20.93182  20.92116    7727       301        3       272  9.836065e+18   \n",
       "75509  18.92427  18.50794    2078       301        2       107  6.756128e+17   \n",
       "22940  16.69879  16.67672    3894       301        1       238  2.051524e+18   \n",
       "59108  16.77130  15.99146    3900       301        5       604  3.304670e+18   \n",
       "30418  21.58270  20.54644    7718       301        2       122  1.062195e+19   \n",
       "43404  17.16317  16.83086    4576       301        6       504  2.286720e+18   \n",
       "11091  16.34801  15.96386    5322       301        2        59  3.094060e+18   \n",
       "40941  21.38046  21.43656    7717       301        4       506  8.826076e+18   \n",
       "35065  17.73182  17.69230    5817       301        2       213  2.748348e+18   \n",
       "17194  19.40892  18.98498    4576       301        1       302  1.281741e+19   \n",
       "\n",
       "       class  redshift  plate    MJD  fiber_ID  \n",
       "27815      1  2.098777   8736  57400       739  \n",
       "75509      1  0.800508    600  52317       265  \n",
       "22940      2  0.000213   1822  53172       488  \n",
       "59108      2 -0.000335   2935  54652       559  \n",
       "30418      0  0.940256   9434  57712       750  \n",
       "43404      0  0.220472   2031  53848        62  \n",
       "11091      0  0.078652   2748  54234       316  \n",
       "40941      1  2.199759   7839  56900       532  \n",
       "35065      2 -0.000280   2441  54065        97  \n",
       "17194      0  0.358106  11384  58522       610  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'/workspaces/ACT-coursework-2/star_classification.csv'\n",
    "df_sdss = pd.read_csv(path)\n",
    "df_sdss['class'] = LabelEncoder().fit_transform(df_sdss['class'])  #changes data from string to integer variables\n",
    "df_sdss.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "05f020cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_used = ['u', 'g', 'r', 'i', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3b261bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_sdss.drop('class', axis=1).values\n",
    "target = df_sdss['class'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "97f7ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 164\n",
    "num_epochs = 25\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c0d6e9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features_scaled, target, test_size = 0.3, random_state = 42)\n",
    "\n",
    "features_train_tensor = torch.tensor(features_train, dtype = torch.float32)\n",
    "target_train_tensor = torch.tensor(target_train, dtype = torch.long)\n",
    "features_test_tensor = torch.tensor(features_test, dtype = torch.float32)\n",
    "target_test_tensor = torch.tensor(target_test, dtype = torch.long)\n",
    "\n",
    "train_set = TensorDataset(features_train_tensor, target_train_tensor)\n",
    "test_set = TensorDataset(features_test_tensor, target_test_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "37572c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0ddd2f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDSSNN(\n",
      "  (fc1): Linear(in_features=17, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SDSSNN(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(SDSSNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(17, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "model = SDSSNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0760be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8f52fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    return torch.sum(preds == labels).item() / len(labels)\n",
    "\n",
    "def train(model, train_dataloader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_acc = 0.0\n",
    "    running_loss = 0.0\n",
    "    for n,(inputs, labels) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_acc += accuracy(outputs,labels)\n",
    "\n",
    "        if (n+1) % 100 ==0:\n",
    "            print(f'Epoch {epoch}, Batch{n+1}, Loss: {running_loss / 100:.4f}, Accuracy: {running_acc / 100:.4f}')\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "\n",
    "\n",
    "def test(model, test_dataloader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += accuracy(outputs, labels)\n",
    "    print(f'test loss: {test_loss/len(test_dataloader):.4f}, Test accuracy: {test_acc / len(test_dataloader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2ffa89e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch100, Loss: 0.6330, Accuracy: 0.7296\n",
      "Epoch 1, Batch200, Loss: 0.2517, Accuracy: 0.9201\n",
      "Epoch 1, Batch300, Loss: 0.2011, Accuracy: 0.9382\n",
      "Epoch 1, Batch400, Loss: 0.1811, Accuracy: 0.9431\n",
      "test loss: 0.2529, Test accuracy: 0.9479\n",
      "Epoch 2, Batch100, Loss: 0.1716, Accuracy: 0.9456\n",
      "Epoch 2, Batch200, Loss: 0.1472, Accuracy: 0.9538\n",
      "Epoch 2, Batch300, Loss: 0.1412, Accuracy: 0.9563\n",
      "Epoch 2, Batch400, Loss: 0.1456, Accuracy: 0.9552\n",
      "test loss: 0.2881, Test accuracy: 0.9484\n",
      "Epoch 3, Batch100, Loss: 0.1442, Accuracy: 0.9550\n",
      "Epoch 3, Batch200, Loss: 0.1262, Accuracy: 0.9607\n",
      "Epoch 3, Batch300, Loss: 0.1304, Accuracy: 0.9595\n",
      "Epoch 3, Batch400, Loss: 0.1290, Accuracy: 0.9597\n",
      "test loss: 0.2802, Test accuracy: 0.9626\n",
      "Epoch 4, Batch100, Loss: 0.1263, Accuracy: 0.9620\n",
      "Epoch 4, Batch200, Loss: 0.1276, Accuracy: 0.9600\n",
      "Epoch 4, Batch300, Loss: 0.1224, Accuracy: 0.9612\n",
      "Epoch 4, Batch400, Loss: 0.1277, Accuracy: 0.9610\n",
      "test loss: 0.2906, Test accuracy: 0.9649\n",
      "Epoch 5, Batch100, Loss: 0.1201, Accuracy: 0.9641\n",
      "Epoch 5, Batch200, Loss: 0.1291, Accuracy: 0.9592\n",
      "Epoch 5, Batch300, Loss: 0.1200, Accuracy: 0.9620\n",
      "Epoch 5, Batch400, Loss: 0.1197, Accuracy: 0.9621\n",
      "test loss: 0.2893, Test accuracy: 0.9643\n",
      "Epoch 6, Batch100, Loss: 0.1086, Accuracy: 0.9666\n",
      "Epoch 6, Batch200, Loss: 0.1205, Accuracy: 0.9631\n",
      "Epoch 6, Batch300, Loss: 0.1163, Accuracy: 0.9651\n",
      "Epoch 6, Batch400, Loss: 0.1165, Accuracy: 0.9629\n",
      "test loss: 0.2995, Test accuracy: 0.9579\n",
      "Epoch 7, Batch100, Loss: 0.1196, Accuracy: 0.9621\n",
      "Epoch 7, Batch200, Loss: 0.1095, Accuracy: 0.9663\n",
      "Epoch 7, Batch300, Loss: 0.1164, Accuracy: 0.9643\n",
      "Epoch 7, Batch400, Loss: 0.1130, Accuracy: 0.9651\n",
      "test loss: 0.2802, Test accuracy: 0.9666\n",
      "Epoch 8, Batch100, Loss: 0.1060, Accuracy: 0.9674\n",
      "Epoch 8, Batch200, Loss: 0.1125, Accuracy: 0.9654\n",
      "Epoch 8, Batch300, Loss: 0.1119, Accuracy: 0.9647\n",
      "Epoch 8, Batch400, Loss: 0.1195, Accuracy: 0.9643\n",
      "test loss: 0.2730, Test accuracy: 0.9634\n",
      "Epoch 9, Batch100, Loss: 0.1151, Accuracy: 0.9646\n",
      "Epoch 9, Batch200, Loss: 0.1139, Accuracy: 0.9654\n",
      "Epoch 9, Batch300, Loss: 0.1038, Accuracy: 0.9692\n",
      "Epoch 9, Batch400, Loss: 0.1157, Accuracy: 0.9639\n",
      "test loss: 0.2654, Test accuracy: 0.9639\n",
      "Epoch 10, Batch100, Loss: 0.1091, Accuracy: 0.9654\n",
      "Epoch 10, Batch200, Loss: 0.1060, Accuracy: 0.9673\n",
      "Epoch 10, Batch300, Loss: 0.1118, Accuracy: 0.9652\n",
      "Epoch 10, Batch400, Loss: 0.1091, Accuracy: 0.9658\n",
      "test loss: 0.2865, Test accuracy: 0.9586\n",
      "Epoch 11, Batch100, Loss: 0.1072, Accuracy: 0.9676\n",
      "Epoch 11, Batch200, Loss: 0.1110, Accuracy: 0.9660\n",
      "Epoch 11, Batch300, Loss: 0.1104, Accuracy: 0.9659\n",
      "Epoch 11, Batch400, Loss: 0.1111, Accuracy: 0.9663\n",
      "test loss: 0.2418, Test accuracy: 0.9667\n",
      "Epoch 12, Batch100, Loss: 0.0961, Accuracy: 0.9693\n",
      "Epoch 12, Batch200, Loss: 0.1101, Accuracy: 0.9670\n",
      "Epoch 12, Batch300, Loss: 0.1053, Accuracy: 0.9677\n",
      "Epoch 12, Batch400, Loss: 0.1099, Accuracy: 0.9660\n",
      "test loss: 0.2539, Test accuracy: 0.9667\n",
      "Epoch 13, Batch100, Loss: 0.1101, Accuracy: 0.9655\n",
      "Epoch 13, Batch200, Loss: 0.1023, Accuracy: 0.9686\n",
      "Epoch 13, Batch300, Loss: 0.1139, Accuracy: 0.9653\n",
      "Epoch 13, Batch400, Loss: 0.1084, Accuracy: 0.9659\n",
      "test loss: 0.2464, Test accuracy: 0.9664\n",
      "Epoch 14, Batch100, Loss: 0.1017, Accuracy: 0.9675\n",
      "Epoch 14, Batch200, Loss: 0.0989, Accuracy: 0.9713\n",
      "Epoch 14, Batch300, Loss: 0.1071, Accuracy: 0.9674\n",
      "Epoch 14, Batch400, Loss: 0.1043, Accuracy: 0.9670\n",
      "test loss: 0.2525, Test accuracy: 0.9642\n",
      "Epoch 15, Batch100, Loss: 0.1000, Accuracy: 0.9701\n",
      "Epoch 15, Batch200, Loss: 0.1048, Accuracy: 0.9690\n",
      "Epoch 15, Batch300, Loss: 0.1066, Accuracy: 0.9659\n",
      "Epoch 15, Batch400, Loss: 0.0992, Accuracy: 0.9693\n",
      "test loss: 0.2380, Test accuracy: 0.9686\n",
      "Epoch 16, Batch100, Loss: 0.1034, Accuracy: 0.9668\n",
      "Epoch 16, Batch200, Loss: 0.1070, Accuracy: 0.9670\n",
      "Epoch 16, Batch300, Loss: 0.0990, Accuracy: 0.9691\n",
      "Epoch 16, Batch400, Loss: 0.1077, Accuracy: 0.9666\n",
      "test loss: 0.2451, Test accuracy: 0.9651\n",
      "Epoch 17, Batch100, Loss: 0.1006, Accuracy: 0.9701\n",
      "Epoch 17, Batch200, Loss: 0.1032, Accuracy: 0.9671\n",
      "Epoch 17, Batch300, Loss: 0.0973, Accuracy: 0.9696\n",
      "Epoch 17, Batch400, Loss: 0.1082, Accuracy: 0.9662\n",
      "test loss: 0.2423, Test accuracy: 0.9615\n",
      "Epoch 18, Batch100, Loss: 0.1000, Accuracy: 0.9693\n",
      "Epoch 18, Batch200, Loss: 0.0974, Accuracy: 0.9688\n",
      "Epoch 18, Batch300, Loss: 0.1053, Accuracy: 0.9680\n",
      "Epoch 18, Batch400, Loss: 0.1062, Accuracy: 0.9674\n",
      "test loss: 0.2276, Test accuracy: 0.9687\n",
      "Epoch 19, Batch100, Loss: 0.0975, Accuracy: 0.9712\n",
      "Epoch 19, Batch200, Loss: 0.0983, Accuracy: 0.9690\n",
      "Epoch 19, Batch300, Loss: 0.1056, Accuracy: 0.9693\n",
      "Epoch 19, Batch400, Loss: 0.0949, Accuracy: 0.9697\n",
      "test loss: 0.2824, Test accuracy: 0.9637\n",
      "Epoch 20, Batch100, Loss: 0.1072, Accuracy: 0.9650\n",
      "Epoch 20, Batch200, Loss: 0.1047, Accuracy: 0.9671\n",
      "Epoch 20, Batch300, Loss: 0.0972, Accuracy: 0.9693\n",
      "Epoch 20, Batch400, Loss: 0.0993, Accuracy: 0.9701\n",
      "test loss: 0.2298, Test accuracy: 0.9682\n",
      "Epoch 21, Batch100, Loss: 0.1025, Accuracy: 0.9684\n",
      "Epoch 21, Batch200, Loss: 0.0976, Accuracy: 0.9691\n",
      "Epoch 21, Batch300, Loss: 0.1056, Accuracy: 0.9672\n",
      "Epoch 21, Batch400, Loss: 0.0931, Accuracy: 0.9715\n",
      "test loss: 0.2279, Test accuracy: 0.9684\n",
      "Epoch 22, Batch100, Loss: 0.0960, Accuracy: 0.9704\n",
      "Epoch 22, Batch200, Loss: 0.1082, Accuracy: 0.9655\n",
      "Epoch 22, Batch300, Loss: 0.0951, Accuracy: 0.9714\n",
      "Epoch 22, Batch400, Loss: 0.0963, Accuracy: 0.9695\n",
      "test loss: 0.2282, Test accuracy: 0.9669\n",
      "Epoch 23, Batch100, Loss: 0.0954, Accuracy: 0.9707\n",
      "Epoch 23, Batch200, Loss: 0.1042, Accuracy: 0.9674\n",
      "Epoch 23, Batch300, Loss: 0.1001, Accuracy: 0.9698\n",
      "Epoch 23, Batch400, Loss: 0.0981, Accuracy: 0.9699\n",
      "test loss: 0.2118, Test accuracy: 0.9691\n",
      "Epoch 24, Batch100, Loss: 0.0966, Accuracy: 0.9704\n",
      "Epoch 24, Batch200, Loss: 0.0989, Accuracy: 0.9690\n",
      "Epoch 24, Batch300, Loss: 0.0955, Accuracy: 0.9702\n",
      "Epoch 24, Batch400, Loss: 0.1001, Accuracy: 0.9692\n",
      "test loss: 0.2019, Test accuracy: 0.9678\n",
      "Epoch 25, Batch100, Loss: 0.0981, Accuracy: 0.9693\n",
      "Epoch 25, Batch200, Loss: 0.0973, Accuracy: 0.9698\n",
      "Epoch 25, Batch300, Loss: 0.0959, Accuracy: 0.9703\n",
      "Epoch 25, Batch400, Loss: 0.1050, Accuracy: 0.9674\n",
      "test loss: 0.1915, Test accuracy: 0.9682\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, train_dataloader, criterion, optimizer, epoch)\n",
    "    test(model, test_dataloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0809f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
